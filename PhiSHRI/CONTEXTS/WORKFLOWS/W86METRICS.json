{
  "door_code": "W86METRICS",
  "semantic_path": "WORKFLOWS.OBSERVABILITY.APPLICATION_METRICS",
  "aliases": [
    "metrics",
    "prometheus",
    "application_metrics",
    "monitoring",
    "gauges",
    "counters",
    "histograms"
  ],
  "context_bundle": {
    "summary": "Application metrics for monitoring: Metric types - Counter (monotonic increasing, e.g., total_requests), Gauge (point-in-time value, e.g., active_connections), Histogram (distribution, e.g., request_duration_seconds), Summary (quantiles, e.g., p95 latency). Prometheus format: Scrape-based (Prometheus pulls /metrics endpoint), labels for dimensions (method, status_code), time-series database. Libraries: prometheus_client (Python), prom-client (Node.js), client_golang (Go). Best practices: Use _total suffix for counters, _seconds for duration, avoid high cardinality labels (user_id bad, status_code good), instrument at application level. Common metrics: http_requests_total, http_request_duration_seconds, error_rate, active_users, queue_depth. Visualization: Grafana dashboards, alerts on thresholds.",
    "prerequisites": [
      "W84LOGGING",
      "W85TRACING",
      "T10OBSERVABILITY"
    ],
    "related_doors": [
      "T17PROMETHEUS",
      "T16GRAFANA",
      "W72CACHING"
    ],
    "onboarding": {
      "quick_start": "Application metrics (Prometheus): Python (prometheus_client): from prometheus_client import Counter, Histogram, Gauge, start_http_server; request_count = Counter('http_requests_total', 'Total HTTP requests', ['method', 'endpoint', 'status']); request_duration = Histogram('http_request_duration_seconds', 'HTTP request duration', ['endpoint']); active_connections = Gauge('active_connections', 'Active connections'); @app.before_request: start_time = time.time(); request.start_time = start_time; active_connections.inc(); @app.after_request: duration = time.time() - request.start_time; request_duration.labels(endpoint=request.path).observe(duration); request_count.labels(method=request.method, endpoint=request.path, status=response.status_code).inc(); active_connections.dec(); start_http_server(8000); # /metrics endpoint. Node.js: const client = require('prom-client'); const register = new client.Registry(); const httpRequestCounter = new client.Counter({ name: 'http_requests_total', help: 'Total requests', labelNames: ['method', 'route', 'status'], registers: [register] }); app.use((req, res, next) => { res.on('finish', () => { httpRequestCounter.inc({ method: req.method, route: req.route?.path, status: res.statusCode }) }); next(); }); app.get('/metrics', (req, res) => { res.set('Content-Type', register.contentType); res.end(register.metrics()) }). Prometheus query: rate(http_requests_total[5m]); # Requests per second. histogram_quantile(0.95, http_request_duration_seconds); # p95 latency. Grafana: Add Prometheus data source, create dashboard with panels.",
      "full_context_path": "/PhiDEX/MASTER_CODEX/03_DEVELOPMENT/DEVELOPMENT_WORKFLOWS_COMPREHENSIVE_GUIDE.md",
      "common_patterns": [
        "Python counter: from prometheus_client import Counter; requests_total = Counter('app_requests_total', 'Total app requests', ['service', 'endpoint']); requests_total.labels(service='api', endpoint='/users').inc()",
        "Python gauge: active_users = Gauge('active_users', 'Currently active users'); active_users.set(get_active_user_count()); # Set to specific value",
        "Python histogram: from prometheus_client import Histogram; request_latency = Histogram('request_duration_seconds', 'Request duration', buckets=[0.1, 0.5, 1.0, 2.0, 5.0]); with request_latency.time(): process_request()",
        "Node.js histogram: const httpDuration = new client.Histogram({ name: 'http_request_duration_seconds', help: 'Duration of HTTP requests', labelNames: ['method', 'route'], buckets: [0.1, 0.5, 1, 2, 5] }); const end = httpDuration.startTimer(); doWork(); end({ method: 'GET', route: '/api/users' })",
        "Go Prometheus: import \"github.com/prometheus/client_golang/prometheus\"; var requestsTotal = prometheus.NewCounterVec(prometheus.CounterOpts{Name: \"http_requests_total\"}, []string{\"method\", \"status\"}); requestsTotal.WithLabelValues(\"GET\", \"200\").Inc()",
        "Custom metrics: business_revenue_total = Counter('revenue_total', 'Total revenue', ['currency']); business_revenue_total.labels(currency='USD').inc(99.99)",
        "Error rate: error_count = Counter('errors_total', 'Total errors', ['type']); try: process(); except ValueError: error_count.labels(type='validation').inc(); raise",
        "Prometheus scrape config: scrape_configs: - job_name: 'my-app'; static_configs: - targets: ['localhost:8000']; scrape_interval: 15s",
        "PromQL queries: sum(rate(http_requests_total[5m])) by (status); # Requests/sec by status. avg(http_request_duration_seconds) by (endpoint); # Avg latency per endpoint",
        "Grafana dashboard: Import dashboard 1860 (Node Exporter), create custom panels with PromQL queries, set alerts on thresholds (e.g., error_rate > 0.05)"
      ],
      "known_errors": []
    },
    "resources": {
      "docs": [
        "/PhiDEX/MASTER_CODEX/03_DEVELOPMENT/DEVELOPMENT_WORKFLOWS_COMPREHENSIVE_GUIDE.md"
      ],
      "code": [],
      "tests": [],
      "errors": []
    },
    "metadata": {
      "last_updated": "2025-11-20T22:00:00Z",
      "confidence": 1.0,
      "usage_count": 0,
      "success_rate": 0.0,
      "tags": [
        "metrics",
        "prometheus",
        "monitoring",
        "counter",
        "gauge",
        "histogram",
        "grafana",
        "observability"
      ],
      "category": "WORKFLOWS",
      "subcategory": "OBSERVABILITY",
      "version": "1.0.0",
      "tested_on": [
        "Python",
        "Node.js",
        "Go",
        "Java",
        "Prometheus",
        "Grafana"
      ],
      "agent_affinity": [
        "VSCC",
        "CMDC",
        "TERMC"
      ],
      "size_bytes": 5686,
      "token_estimate": 1422.0
    }
  }
}
