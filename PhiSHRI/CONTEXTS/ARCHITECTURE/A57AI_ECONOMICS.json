{
  "door_code": "A57AI_ECONOMICS",
  "semantic_path": "ARCHITECTURE.AI.ECONOMICS",
  "aliases": [
    "AI costs",
    "training costs",
    "API pricing",
    "AI economics",
    "inference costs"
  ],
  "context_bundle": {
    "summary": "AI industry economics: training costs, inference pricing, API economics, and the business models driving AI development. Understanding the money behind the models.",
    "prerequisites": [
      "A50AI_LANDSCAPE_2025"
    ],
    "related_doors": [
      "A51DEEPSEEK_ARCHITECTURE",
      "A56TRAINING_EFFICIENCY",
      "A58FRONTIER_MODELS",
      "A59OPEN_MODELS"
    ],
    "onboarding": {
      "quick_start": "Training: $5.5M (DeepSeek final run) to $500M+ (Llama 3). Inference API pricing: DeepSeek $0.27/$1.10, GPT-4o $2.50/$10 per M tokens. DeepSeek 10x cheaper. Open source enables zero marginal cost local inference. Infrastructure capex brutal - Oracle -45% stock. The economics are reshaping the industry.",
      "full_context_path": "",
      "common_patterns": [
        "=== TRAINING COST REALITY ===",
        "DEEPSEEK V3: $5.576M (2.788M H800 hours @ $2/hr) - FINAL RUN ONLY",
        "LLAMA 3 405B: ~$500M+ estimated total cost",
        "GPT-4: ~$100M+ training cost (Sam Altman statement)",
        "GEMINI: Likely $100M+ range",
        "CAVEAT: Public figures are marketing. Exclude R&D, data, failed runs, salaries.",
        "=== TRUE COST COMPONENTS ===",
        "FINAL RUN: The compute for successful training run. What's reported.",
        "ABLATIONS: Experiments to find right architecture/hyperparameters. 5-10x final run.",
        "FAILED RUNS: Training runs that diverged or produced bad models.",
        "DATA: Acquisition, cleaning, curation, quality filtering. Expensive.",
        "R&D: Research, engineering, architecture exploration.",
        "INFRASTRUCTURE: Hardware depreciation, power, cooling, networking.",
        "SALARIES: Top ML researchers cost $500K-2M+/year.",
        "TRUE MULTIPLIER: Real cost likely 5-20x the 'training cost' figure.",
        "=== GPU RENTAL ECONOMICS ===",
        "H100 CLOUD: $2-4/hour depending on provider, term, volume",
        "H800: ~$2/hour (DeepSeek's assumption)",
        "A100: $1-2/hour (older gen, still capable)",
        "CONSUMER RTX: $0.20-0.50/hour equivalent for local",
        "OWNERSHIP: Buy vs rent depends on utilization and time horizon.",
        "=== API PRICING (DEC 2025) ===",
        "--- Per Million Tokens (Input/Output) ---",
        "DEEPSEEK V3.2: $0.27 / $1.10 (best value frontier)",
        "GPT-4o: $2.50 / $10.00",
        "GPT-4o-mini: $0.15 / $0.60 (budget option)",
        "CLAUDE SONNET 4.5: $3.00 / $15.00",
        "CLAUDE HAIKU 4.5: $0.25 / $1.25",
        "GEMINI 3 PRO: $1.25 / $5.00",
        "NOTE: Prices change frequently. Verify before planning.",
        "=== COST RATIOS ===",
        "DEEPSEEK vs GPT-4o: 10x cheaper per token",
        "DEEPSEEK vs CLAUDE SONNET: 11x cheaper",
        "OPEN SOURCE LOCAL: Zero marginal cost (just electricity + depreciation)",
        "=== REASONING MODEL PREMIUM ===",
        "o3 FULL: Up to 600x more expensive than GPT-4o on complex tasks",
        "o3-MINI: 10-20x GPT-4o (more reasonable)",
        "WHY: More thinking tokens = more compute = more cost",
        "VARIABLE: Simple tasks much cheaper than benchmarks suggest",
        "=== INFERENCE ECONOMICS ===",
        "CAPITAL COST: GPUs expensive. Must amortize over many tokens.",
        "UTILIZATION: Higher utilization = lower cost per token.",
        "BATCHING: Serving multiple requests simultaneously improves efficiency.",
        "MARGIN: API price >> compute cost. Providers take 50-80% margin.",
        "=== OPEN SOURCE VALUE PROPOSITION ===",
        "API MARGIN: Open source eliminates provider margin.",
        "LOCAL COST: Electricity + GPU depreciation only.",
        "EXAMPLE: RTX 5070 Ti (~$750) + electricity (~$0.15/kWh)",
        "BREAK-EVEN: Heavy users break even vs API in months.",
        "PRIVACY: Data never leaves machine. No per-token charge for sensitive work.",
        "=== INFRASTRUCTURE REALITY CHECK ===",
        "ORACLE: -45% stock after $12B quarterly capex. Infrastructure brutal.",
        "DATACENTER: Power, cooling, land, construction all expensive.",
        "LEAD TIMES: H100 allocation months out. Supply constrained.",
        "POWER: AI clusters consume megawatts. Power availability a constraint.",
        "=== BUSINESS MODEL DYNAMICS ===",
        "OPENAI: API revenue + ChatGPT subscriptions + enterprise",
        "ANTHROPIC: API revenue + enterprise focus",
        "GOOGLE: AI integrated into existing products (Search, Workspace)",
        "META: Open source as moat destruction + platform play",
        "DEEPSEEK: Efficiency as differentiator + hedge fund backing",
        "=== PRICING PRESSURE ===",
        "RACE TO BOTTOM: DeepSeek forcing price competition",
        "COMMODITIZATION: Base capabilities becoming commodity",
        "DIFFERENTIATION: Moving to reasoning, agents, enterprise features",
        "OPEN SOURCE: Continuous pressure from free alternatives",
        "=== ENTERPRISE vs CONSUMER ===",
        "ENTERPRISE: Higher prices, SLAs, security, compliance, support",
        "CONSUMER: Lower prices, best-effort, limited support",
        "GAP: 2-10x price difference for same model capabilities",
        "=== TOKEN ECONOMICS ===",
        "PROMPT (INPUT): Cheaper. Just reading and embedding.",
        "COMPLETION (OUTPUT): More expensive. Generating new tokens.",
        "RATIO: Output typically 3-5x cost of input.",
        "OPTIMIZATION: Minimize output tokens for cost-sensitive applications.",
        "=== COST OPTIMIZATION STRATEGIES ===",
        "MODEL SELECTION: Use smallest model that works for task.",
        "CACHING: Cache common prompts/responses.",
        "BATCHING: Batch similar requests.",
        "PROMPT ENGINEERING: Shorter prompts, fewer output tokens.",
        "HYBRID: Local for volume, API for complex/rare queries.",
        "=== PHIVECTOR ECONOMICS ===",
        "LOCAL FIRST: Maximize local inference for cost control.",
        "API FALLBACK: Use API for tasks exceeding local capability.",
        "OPEN SOURCE: Leverage free models where they suffice.",
        "EFFICIENCY: PhiSHRI reduces unnecessary LLM calls.",
        "SOVEREIGNTY: No vendor lock-in. Switch providers freely."
      ],
      "known_errors": [
        "PRICE VOLATILITY: API prices change frequently. These are Dec 2025 snapshots.",
        "HIDDEN COSTS: Training cost claims exclude most real costs. True cost 5-20x higher.",
        "REASONING VARIANCE: Reasoning model costs vary wildly by task complexity.",
        "ENTERPRISE PRICING: Enterprise tiers often have opaque, negotiated pricing.",
        "LOCAL COST CALC: Easy to underestimate power, depreciation, maintenance costs.",
        "COMPARISON DIFFICULTY: Different context lengths, features, quality make apples-to-apples hard.",
        "CURRENCY: USD assumed. International pricing varies."
      ]
    },
    "resources": {
      "docs": [
        "https://openai.com/api/pricing/",
        "https://anthropic.com/pricing/",
        "https://platform.deepseek.com/pricing",
        "https://cloud.google.com/vertex-ai/pricing"
      ],
      "code": [],
      "tests": [],
      "errors": []
    },
    "metadata": {
      "last_updated": "2025-12-19T10:45:00.000000000+00:00",
      "confidence": 0.9,
      "tags": [
        "economics",
        "costs",
        "pricing",
        "api",
        "business",
        "training-cost",
        "inference-cost"
      ],
      "category": "ARCHITECTURE",
      "subcategory": "AI",
      "version": "2.0.0",
      "agent_affinity": [
        "DC"
      ],
      "size_bytes": 7763,
      "token_estimate": 1941.0
    }
  }
}
