{
  "door_code": "A55AGENTIC_TRAINING",
  "semantic_path": "ARCHITECTURE.AI.AGENTIC_TRAINING",
  "aliases": [
    "agent training",
    "tool use training",
    "agentic AI",
    "AI agents",
    "function calling",
    "tool calling"
  ],
  "context_bundle": {
    "summary": "Training LLMs for agentic capabilities: tool use, multi-step reasoning, environment interaction, and the shift toward AI agents. The direction ALL major labs are heading.",
    "prerequisites": [
      "A50AI_LANDSCAPE_2025",
      "A51DEEPSEEK_ARCHITECTURE"
    ],
    "related_doors": [
      "A60REASONING_MODELS",
      "A58FRONTIER_MODELS",
      "A62AI_SAFETY_ALIGNMENT"
    ],
    "onboarding": {
      "quick_start": "Agentic training = teach models to use tools, operate in environments, and complete multi-step tasks. DeepSeek: 1,800 synthetic environments, 85,000 tasks. Key methods: GRPO for RL, tool-use SFT, environment simulation. All major labs pivoting this direction. Our DC/KALIC architecture mirrors this pattern.",
      "full_context_path": "",
      "common_patterns": [
        "=== THE AGENTIC SHIFT ===",
        "OLD PARADIGM: Model as oracle. Ask question, get answer. Single turn.",
        "NEW PARADIGM: Model as agent. Given goal, model plans, uses tools, iterates to completion.",
        "WHY: Real tasks require multiple steps, external data, tool use. Chat alone insufficient.",
        "INDUSTRY: ALL major labs investing heavily. DeepSeek, OpenAI, Anthropic, Google.",
        "=== WHAT AGENTS DO ===",
        "TOOL CALLING: Invoke external functions (search, calculator, APIs).",
        "CODE EXECUTION: Write and run code to solve problems.",
        "WEB BROWSING: Navigate websites, extract information.",
        "FILE OPERATIONS: Read, write, modify files.",
        "COMPUTER USE: Screenshots, mouse clicks, keyboard input (Anthropic Claude).",
        "MULTI-STEP REASONING: Plan, execute, observe, adjust.",
        "=== TOOL CALLING MECHANICS ===",
        "FORMAT: Model outputs structured tool calls (JSON/XML).",
        "EXECUTION: System executes tool, returns results.",
        "CONTINUATION: Model sees results, continues reasoning or calls more tools.",
        "LOOP: Plan → Tool Call → Observe → Adjust → Repeat until done.",
        "=== DEEPSEEK'S AGENTIC TRAINING ===",
        "SCALE: 1,800+ synthetic environments, 85,000+ complex prompts.",
        "DOMAINS: Code agents, search agents, code interpreter, general agents.",
        "METHOD: Generate training data at scale via synthesis pipeline.",
        "INTEGRATION: Reasoning into tool-use scenarios. Think while acting.",
        "RESULT: Models that can use tools effectively, not just chat.",
        "=== TRAINING DATA SYNTHESIS ===",
        "ENVIRONMENTS: Programmatically generate diverse task scenarios.",
        "TASKS: Specify goal, available tools, expected trajectory.",
        "TRAJECTORIES: Generate (or collect) successful task completions.",
        "FILTERING: Remove failures, keep successful examples.",
        "DIVERSITY: Vary tools, domains, difficulty, step count.",
        "=== REINFORCEMENT LEARNING APPROACHES ===",
        "GRPO (DeepSeek): Group Relative Policy Optimization. No separate reward model needed.",
        "RLVR: Reinforcement Learning with Verifiable Rewards. Use checkable tasks (math, code).",
        "RLHF: Reinforcement Learning from Human Feedback. Traditional, expensive.",
        "CONSTITUTIONAL AI: Self-critique against principles. Less human labeling.",
        "=== GRPO DETAILS ===",
        "CONCEPT: Compare multiple outputs from same prompt. Reward better ones.",
        "ADVANTAGE: No separate reward model to train and maintain.",
        "KL ESTIMATOR: Unbiased estimator prevents distribution drift.",
        "OFF-POLICY: Can use stored trajectories, not just live generation.",
        "DEEPSEEK USE: Primary RL method for post-training. 10%+ of pre-training compute.",
        "=== THINKING WITH TOOLS ===",
        "CONCEPT: Model reasons about which tools to use, not just calls them.",
        "VISIBLE THINKING: Reasoning traces show tool selection logic.",
        "BENEFITS: Better tool choice, error recovery, explainability.",
        "DEEPSEEK: Explicit 'thinking with tools' capability in V3.2.",
        "=== MULTI-STEP REASONING ===",
        "CHAIN: Break complex task into steps. Execute each, verify, continue.",
        "VERIFICATION: Check intermediate results. Catch errors early.",
        "BACKTRACKING: If step fails, reconsider approach.",
        "PLANNING: Explicit planning phase before execution.",
        "=== ENVIRONMENT TYPES ===",
        "CODE SANDBOXES: Execute Python, check outputs, iterate.",
        "WEB SIMULATORS: Simulated websites for browsing training.",
        "FILE SYSTEMS: Virtual file systems for file operations.",
        "API MOCKS: Simulated external APIs with realistic responses.",
        "GAMES/PUZZLES: Structured environments with clear success criteria.",
        "=== EVALUATION CHALLENGES ===",
        "BENCHMARK LIMITATIONS: Static benchmarks don't capture agentic capability.",
        "ENVIRONMENT VARIANCE: Real environments differ from training.",
        "LONG-HORIZON: Multi-step tasks hard to evaluate automatically.",
        "SAFETY: Agent actions in real world have real consequences.",
        "=== SAFETY CONSIDERATIONS ===",
        "TOOL RESTRICTIONS: Limit which tools agents can access.",
        "CONFIRMATION: Require human approval for dangerous actions.",
        "SANDBOXING: Run agents in isolated environments.",
        "MONITORING: Log all actions for review.",
        "GUARDRAILS: Hard limits on certain action types.",
        "=== ANTHROPIC CLAUDE APPROACH ===",
        "COMPUTER USE: Screenshots, mouse, keyboard control.",
        "SAFETY FIRST: Extensive guardrails, human oversight.",
        "INCREMENTAL: Careful rollout, learn from deployments.",
        "TRANSPARENCY: Clear documentation of capabilities and limits.",
        "=== OPENAI APPROACH ===",
        "PLUGINS: Third-party tool ecosystem.",
        "BROWSING: Built-in web browsing capability.",
        "CODE INTERPRETER: Sandboxed Python execution.",
        "FUNCTION CALLING: Structured tool call format.",
        "=== GOOGLE APPROACH ===",
        "WORKSPACE INTEGRATION: Deep hooks into Docs, Sheets, Gmail, etc.",
        "ANTIGRAVITY: Agentic coding platform.",
        "SEARCH GROUNDING: Use Google Search as tool.",
        "MULTI-MODAL: Tools for image, video, audio processing.",
        "=== PHIVECTOR RELEVANCE ===",
        "DC/KALIC: Our agent split mirrors specialist training pattern.",
        "MCP TOOLS: Our tool ecosystem is exactly what agentic models need.",
        "PHISHRI: Knowledge retrieval as tool. Agents can query doors.",
        "ORCHESTRATION: DC as orchestrator = agentic pattern.",
        "VALIDATION: Industry heading where we're building. Right direction."
      ],
      "known_errors": [
        "SYNTHETIC GAP: Models trained on synthetic data may fail on real environments.",
        "DISTRIBUTION SHIFT: Training tools differ from deployment tools.",
        "ERROR COMPOUNDING: Each step has failure probability. Multi-step = compounded risk.",
        "SAFETY RISKS: Real tool use has real consequences. Careful deployment needed.",
        "OVERFITTING: Models may memorize training trajectories, not generalize.",
        "EVALUATION: Hard to benchmark agentic capabilities meaningfully.",
        "COST: RL training expensive. 10%+ of pre-training compute for DeepSeek.",
        "INSTABILITY: RL can be unstable. Reward hacking, mode collapse, drift."
      ]
    },
    "resources": {
      "docs": [
        "https://arxiv.org/abs/2512.02556 (DeepSeek V3.2 - agentic training details)",
        "https://docs.anthropic.com/en/docs/agents-and-tools/computer-use",
        "https://platform.openai.com/docs/guides/function-calling",
        "https://arxiv.org/abs/2402.14083 (GRPO paper)"
      ],
      "code": [],
      "tests": [],
      "errors": []
    },
    "metadata": {
      "last_updated": "2025-12-19T10:15:00.000000000+00:00",
      "confidence": 0.95,
      "tags": [
        "agentic",
        "agents",
        "tool-use",
        "reasoning",
        "training",
        "rl",
        "grpo",
        "function-calling"
      ],
      "category": "ARCHITECTURE",
      "subcategory": "AI",
      "version": "2.0.0",
      "agent_affinity": [
        "DC",
        "KALIC"
      ],
      "size_bytes": 8502,
      "token_estimate": 2126.0
    }
  }
}
